---
title: "Covid effect on climate hoax"
output: html_document
css:    mondstyle.css
editor_options: 
chunk_output_type: inline

---


<!--html_preserve-->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-3928947-4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-3928947-4');
  </script>
<!--/html_preserve-->


Last update:  `r format(Sys.time(), '%B %d , %Y - %H:%M ')`

```{r Notes,eval=FALSE,include=FALSE}
#We are using this: https://www.earthdatascience.org/courses/earth-analytics/get-data-using-apis/use-twitter-api-r/

#This is useful too: https://rtweet.info/

```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rtweet)
library(tidytext)

# plotting and pipes - tidyverse!
library(ggplot2)
library(dplyr)
library(gdata)



source("../code/gettoken.R")


```







```{r combine timelines}

vselect= c("created_at",
           "user_id","status_id","text","location")
  

flist=list.files("../data/timelines/")

# Get existing combination file
if (file.exists("../data/timelines.txt")) { tlines=dget("../data/timelines.txt")
} else {
  # Create empty start
  name=paste0("../data/timelines/",flist[1])
  cf=dget(name) 
  cf=subset(cf, select = vselect)
  tlines=cf[FALSE,]
}

tlines=subset(tlines, select = vselect)


for(i in flist){
  
    finf <- file.info(paste0("../data/timelines/",i), extra_cols = FALSE)
    
  
    name=paste0("../data/timelines/",i)
    print(name)

    cf=dget(name)  %>% subset(., select = vselect)
    
    tlines=rbind(tlines,cf) %>% distinct(user_id,status_id, .keep_all = TRUE) 

}

dput(tlines, file = "../data/timelines.txt", control = c("keepNA", "keepInteger", "showAttributes"))




```


```{r combine tlines with user info}

#texts['hoaxer']=TRUE
#textsref['hoaxer']=FALSE


tlines=tlines%>%merge(users ,by="user_id")

tlines=tlines%>% mutate(hoaxer=itweets>0)


#how many?

howmany=tlines %>% distinct(user_id, .keep_all = TRUE) %>%group_by(hoaxer) %>% summarise(nn=n())

#ctexts=rbind(texts,textsref)
ctexts=tlines

```







```{r analyse over time}


library(lubridate)

start.date = ymd_hms("2019-01-01 00:00:00")
end.date   = as_datetime(now()) #ymd_hms("2020-04-02 01:00:00")
#end.date   = ymd_hms("2020-04-04 01:00:00")

breaks = seq(start.date, end.date, "1 week")



ctexts['week'] = cut(ctexts$created_at, breaks=breaks)









ctexts['trumpid'] <-  mapply(grepl, pattern="trump", x=tolower(ctexts$text) )



ctexts['climateid'] <-  mapply(grepl, pattern="climate", x=tolower(ctexts$text) )
ctexts['hoaxid']    <-  mapply(grepl, pattern="hoax", x=tolower(ctexts$text) )

ctexts=ctexts%>%mutate(climateXhoaxid=climateid==TRUE & hoaxid==TRUE)
```



```{r prep covid data}

start.date = ymd_hms("2019-01-01 00:00:00")
end.date   = as_datetime(now()) #ymd_hms("2020-04-02 01:00:00")
#end.date   = ymd_hms("2020-04-04 01:00:00")

breaks = seq(start.date, end.date, "1 week")

statsbyd=readRDS(file="../results/statsbyd.Rda")

#make weekly

statsbyd=statsbyd%>%mutate(xdate=as_datetime(date))

names(statsbyd)
statsbyd['week'] = cut(statsbyd$xdate, breaks=breaks)
astatsbyd=statsbyd%>%filter(is.na(week)==FALSE)%>%group_by(week,state)%>%
     summarise(deathsPC=sum(deathsPC),casesPC=sum(casesPC)) 


```



```{r clean up state names}
library(tidyverse)
library(readxl)
sc=read_excel("../data/state_centroids.xlsx")
sc['state']=gsub(", the USA", "",sc$state_raw) %>% gsub(", the US", "",.) %>% gsub(", USA", "",.) %>% gsub("Washington State", "Washington",.)%>% gsub("Missouri State", "Missouri",.)
sn=read_excel("../data/statenames.xlsx")
sn=sn%>% merge(sc , by="state", all.y=TRUE)
sn=subset(sn, select = -state_raw)
```




```{r aggregate}

actexts=ctexts%>%group_by(week,hoaxer)%>%summarize(climateid=sum(climateid),climateXhoaxid=sum(climateXhoaxid),hoaxid=sum(hoaxid),tweets=n())

actexts=actexts%>%mutate(date=ymd(week),climateXhoaxidsh=climateXhoaxid/tweets,cliXhoaxOcli=climateXhoaxid/climateid,climateidsh=climateid/tweets,hoaxsh=hoaxid/tweets)
#scomb=scomb%>% mutate( date=ymd(sixh))
actexts=actexts %>% filter(date>"2019-10-01")

```

```{r deal with us data}
#<<<< combine with us covid data
comb=dget( file = "../data/comb.txt")
comb['ignorance'] <-    mapply(grepl, pattern="#hoax", x=tolower(comb$text) )          |
                        mapply(grepl, pattern="#coronahoax", x=tolower(comb$text) )    | 
                        mapply(grepl, pattern="#covidhoax", x=tolower(comb$text) )     
            #|                      mapply(grepl, pattern="#chinesevirus", x=tolower(comb$text) )


comb_us=comb[(comb$ss>0 & comb$ss<=2) |  
               is.na(comb$lat)==FALSE,
             c("user_id",
               "status_id",
               "ignorance",
               "location",
               "state2dig",
               "lat","lng",
               "text","sixh")]


comb_us$state2dig=trim(comb_us$state2dig)
comb_us=comb_us%>%merge(sn, by="state2dig", all.x=TRUE)
#comb_us=comb_us%>% mutate(lat = replace_na(lat, latc))
us_users=comb_us %>% select(user_id,state2dig,state) %>% distinct(user_id,.keep_all = TRUE)
ctexts_us=ctexts%>%merge(us_users,by=c("user_id"),all.x=TRUE)  %>%   filter(state!="")
summary(ctexts_us$hoaxer)
summary(ctexts_us$state)


statactexts_us=ctexts_us%>% group_by(state,hoaxer,week)%>%
  summarize(climateid=sum(climateid),
            climateXhoaxid=sum(climateXhoaxid),
            hoaxid=sum(hoaxid),tweets=n())

statactexts_us=statactexts_us%>%mutate(date=ymd(week),climateXhoaxidsh=climateXhoaxid/tweets,cliXhoaxOcli=climateXhoaxid/climateid,climateidsh=climateid/tweets,hoaxsh=hoaxid/tweets)


statactexts_us=statactexts_us%>% merge(astatsbyd,by=c("state","week"),all.x=TRUE)%>% 
  mutate(casesPC=ifelse(is.na(casesPC),0,casesPC))




#>>>>

actexts_us=ctexts_us%>%group_by(week,hoaxer)%>%summarize(climateid=sum(climateid),climateXhoaxid=sum(climateXhoaxid),hoaxid=sum(hoaxid),tweets=n())

actexts_us=actexts_us%>%mutate(date=ymd(week),climateXhoaxidsh=climateXhoaxid/tweets,cliXhoaxOcli=climateXhoaxid/climateid,climateidsh=climateid/tweets,hoaxsh=hoaxid/tweets)
#scomb=scomb%>% mutate( date=ymd(sixh))
actexts_us=actexts_us %>% filter(date>"2019-10-01")






```

```{r plots}


ggplot(actexts , aes(x = date,y=cliXhoaxOcli,color=hoaxer  )  )+geom_point() +  geom_line() + theme_minimal() + xlab("Time") +ylab("Share in %")


ggplot(actexts_us , aes(x = date,y=cliXhoaxOcli,color=hoaxer  )  )+geom_point() +  geom_line() + theme_minimal() + xlab("Time") +ylab("Share in %")

```


```{r regressions}


summary(lm(cliXhoaxOcli~casesPC+factor(hoaxer)+factor(state)+factor(date),statactexts_us))
summary(lm(cliXhoaxOcli~casesPC+casesPC:factor(hoaxer)+factor(hoaxer)+factor(state)+factor(date),statactexts_us ))


```

```{r more plots}

ggplot(actexts , aes(x = date,y=cliXhoaxOcli,color=hoaxer  )  )+geom_point() +  geom_line() + theme_minimal() + xlab("Time") +ylab("Share in %")




ggplot(actexts , aes(x = date,y=climateXhoaxid,color=hoaxer  )  )+geom_point() +  geom_line() + theme_minimal() + xlab("Time") +ylab("Share in %")


ggplot(actexts , aes(x = week,y=climateidsh,color=hoaxer  )  )+geom_point() +  geom_line() + theme_minimal() + xlab("Time") +ylab("Share in %")
#tsp2
ggplot(actexts )  +  geom_line( aes(x = date,y=hoaxsh, color=hoaxer  )) + geom_line( aes(x = date,y=climateXhoaxidsh, color=hoaxer  ))+
               theme_minimal() + xlab("Time") +ylab("Share in %")


ggplot(actexts )+ geom_line( aes(x = date,y=climateXhoaxidsh, color=hoaxer  ))+
               theme_minimal() + xlab("Time") +ylab("Share in %")

ggplot(actexts , aes(x = week,y=tweets,color=hoaxer  )  )+geom_point() +  geom_line() + theme_minimal() + xlab("Time") +ylab("Share in %")




tr2=lm(climateid~hoaxer,ctexts)
tr3=lm(climateXhoaxid~hoaxer,ctexts)

tr=lm(trumpid~hoaxer,ctexts)
#summary(tr)
summary(tr2)
summary(tr3)




```



For comparison, here is a word cloud of the 300 most prolific non-hoaxist covid related tweeters. Trump is relevant here too although do a smaller degree: hoaxers have a  `r round(tr$coefficients[["hoaxerTRUE"]]*100,2) ` percentage point higher probability of mentioning Trump (The share of Trump mentions across both groups is `r round(mean(ctexts$trumpid)*100,2)`%). Of course it might also be that one group is supporting Trump whereas the other is opposing him. We will address this in future work. 




```{r nonhoaxer,cache=TRUE,echo=FALSE}
wc(textsref)


```



Also note that the term "filmyourhospital" shows up prominently, which according [reports](https://www.mediamatters.org/coronavirus-covid-19/coronavirus-denying-conspiracy-theory-hashtag-spreading-tiktok-infowars-host) is a hastag pushed by right-wing commentators.


