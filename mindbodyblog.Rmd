---
title: "Infections of the body and the mind"
output: bookdown::html_document2
#output: bookdown::word_document2
css:    mondstyle.css
editor_options: 
chunk_output_type: inline
header-includes:
   - \usepackage{floatrow}
   - \floatsetup[figure]{capposition=top}

---

**by  [Ralf Martin](https://www.imperial.ac.uk/people/r.martin)^[Imperial College Business School  & Centre for Economic Perforamnce, London School of Economics]** 


<!--html_preserve-->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-3928947-4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-3928947-4');
  </script>
<!--/html_preserve-->


```{r Notes,eval=FALSE,include=FALSE}
#We are using this: https://www.earthdatascience.org/courses/earth-analytics/get-data-using-apis/use-twitter-api-r/

#This is useful too: https://rtweet.info/

```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rtweet)
library(tidytext)

# plotting and pipes - tidyverse!
library(ggplot2)
library(dplyr)
library(gdata)



source("../code/gettoken.R")


```





```{r load ts data,include=FALSE}
#`r ntweets'

scomb=readRDS("../results/scomb.rda")

ntweets= round(sum(scomb$tweets) /10^6,2)



nhoax=sum(scomb$igtweets)

```




The coronavirus pandemic has changed everything overnight. Unfortunately, as the genetic sequence of the virus started to make its deadly journey through bodies around the world, in parallel a memetic sequence emerged in the minds of some people: the idea that covid19 pandemic is not real and a hoax. Indeed, the worry is that the two infections exist in a symbiotic relationship with one helping to advance the survival and spread of the other because widespread believe in Hoaxism might prevent people from following guidelines to limit the spread of the pandemic.

To monitor and study this phenomenon we (a team of Imperial College and LSE researchers) have been sampling tweets mentioning the terms “corona” and/or “covid”. Since March 23 we have collected   `r ntweets` million  tweets. We measure hoaxsim by looking for tweets we look for tweets with the hastag hoax (or coronahoax, covidhoax). There was a massive spike in hoaxism around the weekend of March 28 with hoax tweet rates of over 4%. Dis-regarding that hoaxism progresses at a stable rate of about 0.5%.

<br/><br/>


```{r tsplot,echo=FALSE,fig.width=8,fig.height=6,fig.cap="Hoaxism over time"}
tsplot=ggplot(scomb, aes(x = date,y=hoaxsh,color=country  )  )+geom_point() +  geom_line() + theme_minimal() + xlab("Time") +ylab("Share of hoax tweets [%]")

tsplot
```

<br/><br/>


What are the drivers hoaxism? One hypothesis is that hoaxism was driven by the Trump Junta who had a vested interest in downplaying the crisis because of worries that the economic fallout could dampen Trump's re-election chances. We can examine this by looking at word clouds of all tweets by prolific hoaxist tweeters:



```{r wordclouds,include=FALSE, echo=FALSE}

#tmls['ccid'] <-     mapply(grepl, pattern="climate", x=tolower(tmls$text) )
#tmls['trumpid'] <-  mapply(grepl, pattern="trump", x=tolower(tmls$text) )
#tmls['clintonid'] <-  mapply(grepl, pattern="clinton", x=tolower(tmls$text) )  
#tmls['coronaORcovid'] <-     mapply(grepl, pattern="corona", x=tolower(tmls$text) ) |  mapply(grepl, pattern="covid", x=tolower(tmls$text) )
#summary(tmls$trumpid)
#summary(tmls$clintonid)
#summary(tmls$coronaORcovid)
#cc=tmls%>%filter(ccid==TRUE)
#nrow(tmls%>%filter(ccid==TRUE))

library(tm)



tmls=readRDS("../results/tmls.rda")
tmlsnon=readRDS("../results/tmlsnon.rda")


texts=tmls[,c('status_id','text')]


texts=texts%>%dplyr::rename(doc_id=status_id)


textsref=tmlsnon[,c('status_id','text')]
textsref=textsref%>%dplyr::rename(doc_id=status_id)






#install.packages("wordcloud")
library(wordcloud)
#install.packages("RColorBrewer")
library(RColorBrewer)
#install.packages("wordcloud2")
library(wordcloud2)


wc=function(texts){
    texts$text=gsub(" re ", " ", texts$text)
    texts$text=gsub("untuk", " ", texts$text)
    texts$text=gsub("uuuuuu", " ", texts$text)
    texts$text=gsub("uuuuu", " ", texts$text)
    texts$text=gsub("uuuu", " ", texts$text)
    texts$text=gsub("uuu", " ", texts$text)
    texts$text=gsub("uue", " ", texts$text)
    texts$text=gsub("uu", " ", texts$text)
    texts$text=gsub("más", "", texts$text)
    texts$text=gsub("https\\S*", "", texts$text)
    texts$text=gsub("@\\S*", ""    , texts$text)
    texts$text=gsub("amp", "", texts$text) 
    texts$text=gsub("[\r\n]", "", texts$text)
    texts$text=gsub("[[:punct:]]", "", texts$text)
  
    
    
    docs=Corpus(DataframeSource(texts))
    docs <- docs %>%
      tm_map(removeNumbers) %>%
      tm_map(removePunctuation) %>%
      tm_map(stripWhitespace)
    
    docs <- tm_map(docs, content_transformer(tolower))
    docs <- tm_map(docs, removeWords, stopwords("english"))
    
    dtm <- TermDocumentMatrix(docs) 
    matrix <- as.matrix(dtm) 
    words <- sort(rowSums(matrix),decreasing=TRUE) 
    df <- data.frame(word = names(words),freq=words)
    
    
    set.seed(1234) # for reproducibility 
    wordcloud(words = df$word, freq = df$freq, min.freq = 1,       max.words=100, random.order=FALSE, rot.per=0.2,                colors=brewer.pal(8, "Dark2"))
}
```




```{r wordcloudsregs, cache=TRUE,echo=FALSE, fig.width=8,fig.height=6,fig.cap="Word cloud of hoaxist's tweets"}

wc(texts)
#names(combstream)
#textsref=subset(comb, select = c(status_id,text))
#textsref=textsref%>%rename(doc_id=status_id)
```


<br/><br/>


```{r,echo=FALSE}

texts['hoaxer']=TRUE
textsref['hoaxer']=FALSE


ctexts=rbind(texts,textsref)


ctexts['trumpid'] <-  mapply(grepl, pattern="trump", x=tolower(ctexts$text) )






tr=lm(trumpid~hoaxer,ctexts)
#summary(tr)

```




We find indeed that Trump is a popular term among hoaxists. Indeed we find that his probability of being mentioned by hoaxists is significantly larger than among non hoaxist covid tweeters (`r round((tr$coefficients[["hoaxerTRUE"]]+tr$coefficients[["(Intercept)"]])*100,2)`%  as opposed to `r round((tr$coefficients[["(Intercept)"]])*100,2)`%)


Of course, the big question is if all of this matters for actual covid outcomes? To start answering this, we correlated infection rates (covid19 cases per 1000 residents) with hoaxism infection rates at the level of US states (see Figure 2). It is very striking that New York does not only have record levels of covid infections but also record levels of hoaxism. But of course, there are other states (notably Alaska and Alabahma) with high hoaxism levels but rather low infection rates. Various people have suggested that population density is an important factor in explaining covid infection rates.  A hypothesis that emerges from  our current observations is that what matters is the interaction between the two. This is particularly plausible when comparing New York and New Jersey, which has higher density but lower covid and lower hoaxism rates than New York.
What's more: while we have to be cautious in interpreting correlation as causation, a causal interpretation of our current numbers would imply substantial impacts of hoaxism: For the US as a whole it could suggest that about 30% of covid cases are down to hoaxism. 
Clearly, this warrants further investigation. One issue with the results for New York could be that we lump metropolitian areas of New York city with rather rural areas of New York state.
We will therefore continue to monitor and analyse hoaxists tweets. Updates will be [here](https://mondpanther.github.io/economemics.github.io/mindbody.html).





```{r statelevel,echo=FALSE}



stats=readRDS("../results/stats.Rda")
stats=stats%>%mutate(pop=pop/1000)

r1=lm(casesPC~hoaxsh,stats)
r2=lm(casesPC~hoaxsh+density+pop,stats)


r3=lm(casesPC~hoaxsh+density+pop+tweetsPC,stats)
r4=lm(casesPC~hoaxsh*density+pop+tweetsPC,stats)
r5=lm(casesPC~hoaxsh*density+pop+tweetsPC,stats%>%filter(state!="New York"))



#summary(lm(casesPC~hoaxsh+density,stats%>%filter(hoaxsh<7 & casesPC<10)))
#summary(lm(casesPC~hoaxsh+density,stats%>%filter(state!="New Jersey" & state!="New York")))

#stats=stats%>%mutate(DD=  (r4$coefficients[["hoaxsh"]]+r4$coefficients[["hoaxsh:density"]] * density ) *hoaxsh * pop/1000)
#stats=stats%>%mutate(DD=  (r3$coefficients[["hoaxsh"]]) *hoaxsh * pop)
#sum(stats$DD)
#sum(stats$cases)


#sum(stats$DD)
#sum(stats$cases)

#summary(r1)
#summary(r2)
#summary(r3)
#summary(r4)

sss=stats%>%summarise(pop=sum(pop),cases=sum(cases), tweets=sum(tweets),hoax=sum(hoax))
sss=sss%>% mutate(hoaxsh=hoax/tweets*100,casesPC=cases/pop)
#sss=sss%>% mutate(saved=(r4$coefficients[["hoaxsh"]]+r4$coefficients[["hoaxsh:density"]] * density ) * hoaxsh  *  pop)


coef=r3$coefficients[["hoaxsh"]]


#stats=stats%>% mutate(saved=(r3$coefficients[["hoaxsh"]]) * hoaxsh  *  pop)
#stats=stats%>% mutate(saved=(r4$coefficients[["hoaxsh"]]+r4$coefficients[["hoaxsh:density"]] * density ) * hoaxsh  *  pop)
stats=stats%>% mutate(saved=(r5$coefficients[["hoaxsh"]]+r5$coefficients[["hoaxsh:density"]] * density ) * hoaxsh  *  pop)



stats=stats%>% mutate(saved=ifelse(saved>cases, cases,saved))

#summary(stats$saved)

#look=stats%>% select(c(hoaxsh,saved,casesPC))
#View(look)


stats=stats%>%mutate(hoaxsh2=hoaxsh^2,density2=density^2)
saved=base::sum(stats$saved)
all=base::sum(stats$cases)


#summary(lm(casesPC~hoaxsh+density,stats))
#summary(lm(casesPC~hoaxsh*density+tweetsPC,stats))
#summary(lm(casesPC~hoaxsh*density+tweetsPC+pop,stats))
#summary(lm(casesPC~hoaxsh*density+tweetsPC+pop,stats))


#summary(lm(log(casesPC)~hoaxsh*density+tweetsPC+pop,stats))
#summary(lm(casesPC~density+tweetsPC,stats))
#summary(lm(casesPC~hoaxsh*density+pop+tweetsPC+density2+hoaxsh2,stats%>%filter(state!="New York")))
#summary(lm(casesPC~hoaxsh+density+pop+tweetsPC,stats%>%filter(state!="New York")))

#summary(lm(casesPC~hoaxsh+density+tweetsPC,stats%>%filter(state!="New York")))
```

<br/><br/>


```{r,  echo=FALSE, fig.width=7,fig.height=6,fig.cap="\\label{fig:hoaxscatter}Hoaxism vs Covid Infections"}
library(ggrepel)
ggplot(stats) + 
    aes(y=casesPC, x=hoaxsh,label=state) +
    geom_point() +geom_text_repel(cex=2)+
    stat_smooth(method = "lm", se = FALSE)+theme_minimal()+ylab("Covid Cases per 1000")+xlab("Share of hoax tweets in %")


```



<br/><br/>


```{r,  echo=FALSE,fig.width=7,fig.height=6,fig.cap="\\label{fig:densityscatter}Population density vs Covid Infections"}
library(ggrepel)
ggplot(stats) + 
    aes(y=casesPC, x=density,label=state) +
    geom_point() +geom_text_repel(cex=2)+
    stat_smooth(method = "lm", se = FALSE)+theme_minimal()+ylab("Covid Cases per 1000")+xlab("Density [People per square mile]")


```





