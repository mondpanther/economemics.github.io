---
title: "Infections of the body and the mind"
output: html_document
css:    mondstyle.css
editor_options: 
chunk_output_type: inline

---

**by  [Ralf Martin](https://www.imperial.ac.uk/people/r.martin)^[Imperial College Business School  & Centre for Economic Perforamnce, LSE]** 


<!--html_preserve-->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-3928947-4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-3928947-4');
  </script>
<!--/html_preserve-->


```{r Notes,eval=FALSE,include=FALSE}
#We are using this: https://www.earthdatascience.org/courses/earth-analytics/get-data-using-apis/use-twitter-api-r/

#This is useful too: https://rtweet.info/

```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rtweet)
library(tidytext)

# plotting and pipes - tidyverse!
library(ggplot2)
library(dplyr)
library(gdata)



source("../code/gettoken.R")


```





```{r load ts data,include=FALSE}
#`r ntweets'

scomb=readRDS("../results/scomb.rda")

ntweets= round(sum(scomb$tweets) /10^6,2)



nhoax=sum(scomb$igtweets)

```


 



The coronavirus pandemic has changed everything overnight. Unfortunately, as the genetic sequence of the virus started to make its deadly journey through bodies around the world, in parallel a memetic sequence emerged in the minds of some people: the idea that covid19 pandemic is not real and a hoax. Indeed, the worry is that the two infections exist in a symbiotic relationship with one helping to advance the survival and spread of the other. To monitor and study this phenomenon we have been sampling tweets mentioning the terms “corona” and/or “covid”. Since March 23 we have collected   `r ntweets` million  tweets. We measure hoaxsim by looking for tweets we look for tweets with the hastag hoax (or coronahoax, covidhoax).


What are the drivers hoaxism? One hypothesis is that hoaxism was driven by the Trump Junta who had a vested interest in downplaying the crisis because of worries that the economic impacts of a shutdown could affect Trump's re-election chances.



Some emerging results include the following:

- There is no sign that hoax meme has run its course. Over our admittedly short sample period of about two weeks the overal level of hoaxism remained stable.
- There is some evidence that Donald Trump has to answer for the hoax meme. Hoax believers are particularly obsessed with him.
- There is evidence that believe in Hoax led to more higher covid cases than necessary. Across US states we find a strong correlation between hoax believer rates and covid cases. 
- We have evidence that is consistent with the idea that interaction between population density and hoaxism is a major factor in explaining the severety of the pandemic.
- We have to be careful with causal interpretations but the numbers would imply that US covid cases could be about 50% lower in absence of hoaxism.




# Hoaxism over time

How bad is the hoax infection and is it getting better or worse? To identify tweeters believing in the hoax (or promoting the hoax idea) we look for tweets with one of the following hastags:

- "#hoax"
- "#coronahoax"
- "#covidhoax"
- "#chinesevirus"

Using hashtags instead of string searches of the same terms provides a good distinction between tweets who display support for hoaxsim vs tweets criticising hoaxism. Note that this is likely a conservative way of counting hoaxist tweets and in reality a larger fraction of tweets are from people supporting hoaxist ideas.

Below is a time series plot of the share of hoaxist tweets over our sample period. we report separate series for the Us and UK. Assigning location to tweets is notoriously difficult as most users have switch off detailed location tracking. In the figure below we base location on the analysis of a free text field where users can write something about their whereabouts. In many cases this refers to known areas although the detail varies (e.g. London, UK vs the Universe). Often it also involves phantasy locations (e.g. Walhalla). Hence, our "other" category might include tweeters from either the UK or Us who have chosen not to reveal their location.

Note that towards the begining of the sample period the share of hoax tweets in all covid related tweets is less than 0.5%. However, the weekend  around the 28th of March saw a major outbreak of Hoaxism that was particularly bad in the UK. This has subsided somewhat come March 30. The whole sample trend would suggest that hoaxism is fairly stable and not subsiding.

```{r tsplot,echo=FALSE}
tsplot=ggplot(scomb, aes(x = date,y=hoaxsh,color=country  )  )+geom_point() +  geom_line() + theme_minimal() + xlab("Time") +ylab("Share of hoax tweets [%]")

tsplot
```


```{r, echo=FALSE}
scomb=scomb%>%group_by(date) %>% summarise(tot=sum(tweets)) %>% merge(scomb,by="date") %>% mutate(totsh=tweets/tot *100)
tsp2=ggplot(scomb, aes(x = date,y=totsh,color=country  )  )+geom_point() +  geom_line() + theme_minimal() + xlab("Time") +ylab("Share in %")

#tsp2
```










# Why hoaxism?

What are drives hoaxism? We can start exploring this by looking at the tweets of hoaxists more widely. Below we plot a word cloud of the last 1000 tweets of the 300 most prolific hoaxists. One hypothesis is that hoaxism has been fueled by Trumpism. Because of worries that a strong response to the pandemic could negatively affect the economy and thereby his re-election chances, he had a vested interest in playing down the crisis. The word cloud confirms that obsession with trump is prevalent among hoxists.

```{r wordclouds,include=FALSE, echo=FALSE}

#tmls['ccid'] <-     mapply(grepl, pattern="climate", x=tolower(tmls$text) )
#tmls['trumpid'] <-  mapply(grepl, pattern="trump", x=tolower(tmls$text) )
#tmls['clintonid'] <-  mapply(grepl, pattern="clinton", x=tolower(tmls$text) )  
#tmls['coronaORcovid'] <-     mapply(grepl, pattern="corona", x=tolower(tmls$text) ) |  mapply(grepl, pattern="covid", x=tolower(tmls$text) )
#summary(tmls$trumpid)
#summary(tmls$clintonid)
#summary(tmls$coronaORcovid)
#cc=tmls%>%filter(ccid==TRUE)
#nrow(tmls%>%filter(ccid==TRUE))

library(tm)



tmls=readRDS("../results/tmls.rda")
tmlsnon=readRDS("../results/tmlsnon.rda")


texts=tmls[,c('status_id','text')]


texts=texts%>%dplyr::rename(doc_id=status_id)


textsref=tmlsnon[,c('status_id','text')]
textsref=textsref%>%dplyr::rename(doc_id=status_id)






#install.packages("wordcloud")
library(wordcloud)
#install.packages("RColorBrewer")
library(RColorBrewer)
#install.packages("wordcloud2")
library(wordcloud2)


wc=function(texts){
    texts$text=gsub(" re ", " ", texts$text)
    texts$text=gsub("untuk", " ", texts$text)
    texts$text=gsub("uuuuuu", " ", texts$text)
    texts$text=gsub("uuuuu", " ", texts$text)
    texts$text=gsub("uuuu", " ", texts$text)
    texts$text=gsub("uuu", " ", texts$text)
    texts$text=gsub("uue", " ", texts$text)
    texts$text=gsub("uu", " ", texts$text)
    texts$text=gsub("más", "", texts$text)
    texts$text=gsub("https\\S*", "", texts$text)
    texts$text=gsub("@\\S*", ""    , texts$text)
    texts$text=gsub("amp", "", texts$text) 
    texts$text=gsub("[\r\n]", "", texts$text)
    texts$text=gsub("[[:punct:]]", "", texts$text)
  
    
    
    docs=Corpus(DataframeSource(texts))
    docs <- docs %>%
      tm_map(removeNumbers) %>%
      tm_map(removePunctuation) %>%
      tm_map(stripWhitespace)
    
    docs <- tm_map(docs, content_transformer(tolower))
    docs <- tm_map(docs, removeWords, stopwords("english"))
    
    dtm <- TermDocumentMatrix(docs) 
    matrix <- as.matrix(dtm) 
    words <- sort(rowSums(matrix),decreasing=TRUE) 
    df <- data.frame(word = names(words),freq=words)
    
    
    set.seed(1234) # for reproducibility 
    wordcloud(words = df$word, freq = df$freq, min.freq = 1,       max.words=100, random.order=FALSE, rot.per=0.2,                colors=brewer.pal(8, "Dark2"))
}
```


```{r wordcloudsregs, echo=FALSE}

wc(texts)
#names(combstream)
#textsref=subset(comb, select = c(status_id,text))
#textsref=textsref%>%rename(doc_id=status_id)
```




```{r,echo=FALSE}

texts['hoaxer']=TRUE
textsref['hoaxer']=FALSE


ctexts=rbind(texts,textsref)


ctexts['trumpid'] <-  mapply(grepl, pattern="trump", x=tolower(ctexts$text) )






tr=lm(trumpid~hoaxer,ctexts)
#summary(tr)

```



For comparison, here is a word cloud of the 300 most prolific non-hoaxist covid related tweeters. Trump is relevant here too although do a smaller degree: hoaxers have a  `r round(tr$coefficients[["hoaxerTRUE"]]*100,2) ` percentage point higher probability of mentioning Trump (The share of Trump mentions across both groups is `r round(mean(ctexts$trumpid)*100,2)`%). Of course it might also be that one group is supporting Trump whereas the other is opposing him. We will address this in future work. 




```{r nonhoaxer,echo=FALSE}
wc(textsref)


```



Also note that the term "filmyourhospital" shows up prominently, which according [reports](https://www.mediamatters.org/coronavirus-covid-19/coronavirus-denying-conspiracy-theory-hashtag-spreading-tiktok-infowars-host) is a hastag pushed by right-wing commentators.


# The consequences of memetic infections

We examine if US state level hoax infection rates are correlated with reported covid19 infection rates. This is interesting to gauge if mis-information has any effect on actual outcomes. Clearly, from a simple exercise like that we cannot draw overly strong conclusions about causal effects. However, it is a useful starting point. 
The figure below is a scatter plot of state level per capita infection rates on the share of hoax tweets (in percent) from within the state. There is clearly a positive relationship. What is particularly striking is that New York is not only extreme in terms of infections but also in the prevalenc of hoaxism.

<br/><br/>


```{r, echo=FALSE}
#https://rstudio-pubs-static.s3.amazonaws.com/265609_47fe3e17b8ec4e4792340624f55b3544.html

#```{r sampleani, fig.show='animate', fig.width=4, fig.height=4, cache=FALSE, interval=0.05, aniopts="controls,loop"}
#for (i in 1:50) {
#    plot(x=i/10, y=i/10, xlim=c(0,6), ylim=c(0,6), pch=20, col=palette()[2], cex=5)
#}

```



```{r statelevel,echo=FALSE}



stats=readRDS("../results/stats.Rda")
stats=stats%>%mutate(pop=pop/1000)

r1=lm(casesPC~hoaxsh,stats)
r2=lm(casesPC~hoaxsh+density+pop,stats)


r3=lm(casesPC~hoaxsh+density+pop+tweetsPC,stats)
r4=lm(casesPC~hoaxsh*density+pop+tweetsPC,stats)
r5=lm(casesPC~hoaxsh*density+pop+tweetsPC,stats%>%filter(state!="New York"))



#summary(lm(casesPC~hoaxsh+density,stats%>%filter(hoaxsh<7 & casesPC<10)))
#summary(lm(casesPC~hoaxsh+density,stats%>%filter(state!="New Jersey" & state!="New York")))

#stats=stats%>%mutate(DD=  (r4$coefficients[["hoaxsh"]]+r4$coefficients[["hoaxsh:density"]] * density ) *hoaxsh * pop/1000)
#stats=stats%>%mutate(DD=  (r3$coefficients[["hoaxsh"]]) *hoaxsh * pop)
#sum(stats$DD)
#sum(stats$cases)


#sum(stats$DD)
#sum(stats$cases)

#summary(r1)
#summary(r2)
#summary(r3)
#summary(r4)

sss=stats%>%summarise(pop=sum(pop),cases=sum(cases), tweets=sum(tweets),hoax=sum(hoax))
sss=sss%>% mutate(hoaxsh=hoax/tweets*100,casesPC=cases/pop)
#sss=sss%>% mutate(saved=(r4$coefficients[["hoaxsh"]]+r4$coefficients[["hoaxsh:density"]] * density ) * hoaxsh  *  pop)


coef=r3$coefficients[["hoaxsh"]]


#stats=stats%>% mutate(saved=(r3$coefficients[["hoaxsh"]]) * hoaxsh  *  pop)
#stats=stats%>% mutate(saved=(r4$coefficients[["hoaxsh"]]+r4$coefficients[["hoaxsh:density"]] * density ) * hoaxsh  *  pop)
stats=stats%>% mutate(saved=(r5$coefficients[["hoaxsh"]]+r5$coefficients[["hoaxsh:density"]] * density ) * hoaxsh  *  pop)



stats=stats%>% mutate(saved=ifelse(saved>cases, cases,saved))

#summary(stats$saved)

#look=stats%>% select(c(hoaxsh,saved,casesPC))
#View(look)


stats=stats%>%mutate(hoaxsh2=hoaxsh^2,density2=density^2)
saved=base::sum(stats$saved)
all=base::sum(stats$cases)


#summary(lm(casesPC~hoaxsh+density,stats))
#summary(lm(casesPC~hoaxsh*density+tweetsPC,stats))
#summary(lm(casesPC~hoaxsh*density+tweetsPC+pop,stats))
#summary(lm(casesPC~hoaxsh*density+tweetsPC+pop,stats))


#summary(lm(log(casesPC)~hoaxsh*density+tweetsPC+pop,stats))
#summary(lm(casesPC~density+tweetsPC,stats))
#summary(lm(casesPC~hoaxsh*density+pop+tweetsPC+density2+hoaxsh2,stats%>%filter(state!="New York")))
#summary(lm(casesPC~hoaxsh+density+pop+tweetsPC,stats%>%filter(state!="New York")))

#summary(lm(casesPC~hoaxsh+density+tweetsPC,stats%>%filter(state!="New York")))
```

<br/><br/>



```{r,  echo=FALSE}
library(ggrepel)
ggplot(stats) + 
    aes(y=casesPC, x=hoaxsh,label=state) +
    geom_point() +geom_text_repel(cex=2)+
    stat_smooth(method = "lm", se = FALSE)+theme_minimal()+ylab("Covid Cases per 1000")+xlab("Share of hoax tweets in %")


```

<br/><br/>

An alternative explanation for the striking infection rates in New York is the relative density of New York. That's why we also examine the relationship between infection rates and density (in people per square mile). Indeed there is a positive relationship as well. But New York seems to be more of an outlier in terms of density. 
Indeed one potential hypothesis the two figures combined suggests is that there might be an interaction effect between hoaxism and density. Take for instance Alaska, which has the second highest rates of hoaxism, but much lower infection rates than New York. Of course it's also the least densiley populated state. On the other hand: consider New Jersey which is actually more dense than New York but has much lower rates of infection. It turns out that hoaxism is also less prevalent there.



<br/><br/>


```{r,  echo=FALSE}
library(ggrepel)
ggplot(stats) + 
    aes(y=casesPC, x=density,label=state) +
    geom_point() +geom_text_repel(cex=2)+
    stat_smooth(method = "lm", se = FALSE)+theme_minimal()+ylab("Covid Cases per 1000")+xlab("Density [People per square mile]")


```


<br/><br/>


To explore this more below we also undertake regression analysis. The Table below shows that:

- Hoaxsim is indeed significantly and positively related to hoaxism (Column 1). The coefficient implies that a 1 percentage point higher hoaxism level is associated with 0.822 extra covid patients per 1000 citizens.

- This is result is highly robust to the inclusion of further controls such as population density, population size and covid tweet intensity (covid related tweets per 1000 people) in column 2. 

- The hoaxism and density interaction hypothesis is confirmed in column 3 where we include the interaction of both variables as an additional regression coefficient. In column 4, drop New York from the sample. The interaction hypothesis is robust to that.


We have to be cautious with causal claims at this stage. Our results could be contingent on our  simple model specification or crude aggregation (e.g. we don't take into account that New York state consists of the metropolitian area of New York as well as rarther rural parts). Still, to understand if the results are not only statistically significant but also quantitatively meaningful it is useful to ask what - if taken at face value - the impact of haoxism would be. Using the estimates from column 4 would imply that without hoaxism  we had  `r format(saved,scientific=FALSE)` covid cases less (of `r format(all,scientific=FALSE)`), as of `r max(stats$date)`. Clearly, this is substantial.

<br/><br/>


```{r  message=FALSE, results='asis',echo=FALSE} 
library(stargazer)

stargazer(r1,  r3,r4,r5, type = "html", dep.var.labels   = "Covid19 Cases per capita", covariate.labels = c("Share of Hoax Tweets", "Population density", "Population", "Tweets per capita",
                               "Hoax Tweets $\times$ Density", "Constant"))
```

<br/><br/>

